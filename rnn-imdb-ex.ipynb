{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network: IMDB example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import SimpleRNN, Embedding, Input\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from typing import List\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility:\n",
    "np.random.seed(1234)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_path = './img'\n",
    "\n",
    "if not os.path.isdir(img_path):\n",
    "    os.mkdir(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector space embedding:\n",
    "embedding_dim = 64\n",
    "n_top_freq_words = 10000\n",
    "max_review_length = 100\n",
    "# drop_embed = 0.2\n",
    "\n",
    "# Training:\n",
    "epochs = 16\n",
    "batch_size = 128\n",
    "\n",
    "# RNN layer architecture:\n",
    "#n_rnn = 256\n",
    "#drop_rnn = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, input_train, y_train, input_test, y_test):\n",
    "    model.fit(input_train,  \n",
    "              y_train,\n",
    "              epochs=4,\n",
    "              batch_size=batch_size,\n",
    "              validation_split=0.2)\n",
    "    \n",
    "    score, acc = model.evaluate(input_test, y_test)\n",
    "    \n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model(model):\n",
    "    from IPython.display import Image\n",
    "    from IPython.core.display import HTML \n",
    "    \n",
    "    path = './img/{}.png'.format(model.name)\n",
    "    plot_model(model, to_file=path)\n",
    "    \n",
    "    return Image(url=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_class_seperation(model):\n",
    "    y_test_preds = model.predict_proba(input_test)\n",
    "\n",
    "    plt.hist(y_test_preds)\n",
    "    plt.xlim(0, 1)\n",
    "    _ = plt.axvline(x=0.5, color='red')\n",
    "\n",
    "    \"AUC: {:0.2f}\".format(roc_auc_score(y_test, y_test_preds) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consist of reviews for movies from IMDB, the Internet Movie Database. It contains reviews for 25,000 movies, each labeled by sentiment (positive/negative). Sentiment is encoded as `1` if positive and as `0` otherwise.\n",
    "\n",
    "Fortunately the data has already been preprocessed: each review is encoded as a sequence of word indexes (integers). The word index itself is the position of a word in the list of all unique words contained in all 25,000 movies ordered by their frequency (from most frequent words down to the most uncommon ones). So the word index \"3\" encodes the 3rd most frequent word in the data, which happens to be \"a\" like in \"a movie\".\n",
    "\n",
    "By convention, \"0\" does not stand for a specific word. Instead it is used to encode any unknown word and can be used for padding (see below).\n",
    "\n",
    "Here are some example reviews from IMDB:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Negative review examples:\n",
    "=========================\n",
    "* Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting.\n",
    "* Even those from the era should be turned off.\n",
    "* The cryptic dialogue would make Shakespeare seem easy to a third grader.\n",
    "\n",
    "Positive review examples:\n",
    "=========================\n",
    "* I didn't know this came from Canada, but it is very good. Very good!\n",
    "* I liked this movie a lot. It really intrigued me how Deanna and Alicia became friends over such a tragedy\n",
    "* When I saw the elaborate DVD box for this and the dreadful Red Queen figurine, \n",
    "  I felt certain I was in for a big disappointment, but surprise, surprise, I loved it. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data set and split it intro training and test sets. Notice than we only pick the top `num_words=500` words (by frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=n_top_freq_words, \n",
    "                                                              index_from=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an overview on how big the sets are. As it turns out the data is split in 50% for training and 50% for test. (Note: We cannot specify `test_split` for this data set in the `load_data` function.) As promised there are two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Shape train sequences: (25000,)\n",
      "Shape test sequences: (25000,)\n",
      "Shape train labels: (25000,)\n",
      "Shape test labels: (25000,)\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "\n",
    "print('Shape train sequences:', input_train.shape)\n",
    "print('Shape test sequences:', input_test.shape)\n",
    "print('Shape train labels:', y_train.shape)\n",
    "print('Shape test labels:', y_test.shape)\n",
    "print('Number of classes:', len(np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas to have a look at the first training samples. As said each of them is a list of word indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_index_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 11, 19, 13, 40, 527, 970, 1619, 1382, 62, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 191, 1150, 191, 8252, 75, 225, 2, 3, 1460,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 11, 44, 5, 27, 28, 4, 1, 246, 105, 4, 1, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 2, 2, 30, 2801, 1, 2037, 429, 108, 150,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 246, 1320, 4, 58, 110, 7, 7, 10, 1634, 11,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 word_index_sequence\n",
       "0  [1, 11, 19, 13, 40, 527, 970, 1619, 1382, 62, ...\n",
       "1  [1, 191, 1150, 191, 8252, 75, 225, 2, 3, 1460,...\n",
       "2  [1, 11, 44, 5, 27, 28, 4, 1, 246, 105, 4, 1, 5...\n",
       "3  [1, 1, 2, 2, 30, 2801, 1, 2037, 429, 108, 150,...\n",
       "4  [1, 246, 1320, 4, 58, 110, 7, 7, 10, 1634, 11,..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_train, columns=[\"word_index_sequence\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions loads the word index of the IMDB data set and allows us to translate a word index vector to a human readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(word_indizes: List[int]):\n",
    "    word_index = imdb.get_word_index()\n",
    "    \n",
    "    inverse_word_index = {\n",
    "        index:word \n",
    "        for word, index \n",
    "        in word_index.items()\n",
    "    }\n",
    "    \n",
    "    words = [\n",
    "        inverse_word_index.get(wrd_idx, '<missing-word>') \n",
    "        for wrd_idx \n",
    "        in word_indizes\n",
    "    ]\n",
    "    \n",
    "    review_txt = ' '.join(words)\n",
    "    \n",
    "    return review_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious counter part for encoding a review as a word index vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(review: str):\n",
    "    word_index = imdb.get_word_index()\n",
    "    \n",
    "    encoded_review = [\n",
    "        word_index.get(word, 0) \n",
    "        for word \n",
    "        in review.lower().split(\" \")\n",
    "    ]\n",
    "    \n",
    "    return encoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check everythings works fine by encoding and decoding an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'even those from the era should be turned <missing-word>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Even those from the era should be turned off.\"\n",
    "print(decode(encode(review))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a real training example. (Note: Some words are clearly missing. Remember we limited ourself to the `num_words = 500` when loading the data via `imdb.load_data` above.) The review was favorable and thus gets a sentiment score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"the french horror cinema has seen something of a revival over the last couple of years with great films such as inside and and romance and on to the scene and and the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made and was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is and by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named and sent to prison for fraud he is put in a cell with three others the quietly insane and body building and marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old and after and part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that and makes the best of it's and as despite it's and the film never actually feels restrained and manages to flow well throughout director eric and provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell and that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really and people and this film proves that as the director and that we can never really be sure of exactly what is round the corner and this helps to ensure that and actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall and is a truly great horror film and one of the best of the decade highly recommended viewing\"\n",
      "\n",
      "Sentiment:  1\n"
     ]
    }
   ],
   "source": [
    "print('Review: \"{}\"\\n'.format(decode(input_train[10])))\n",
    "print('Sentiment: ', y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = sequence.pad_sequences(input_train, maxlen=max_review_length)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_train shape: (25000, 100)\n",
      "input_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1412,   30,    3,   19,    9,  212,   25,   74,   49,    2,   11,\n",
       "        404,   13,   79,    2,    5,    1,  104,  114, 5949,   12,  253,\n",
       "          1,    2,    4, 3763,    2,  720,   33,   68,   40,  527,  473,\n",
       "         23,  397,  314,   43,    4,    1,    2, 1026,   10,  101,   85,\n",
       "          1,  378,   12,  294,   95,   29, 2068,   53,   23,  138,    3,\n",
       "        191, 7483,   15,    1,  223,   19,   18,  131,  473,   23,  477,\n",
       "          2,  141,   27, 5532,   15,   48,   33,   25,  221,   89,   22,\n",
       "        101,    1,  223,   62,   13,   35, 1331,   85,    9,   13,  280,\n",
       "          2,   13, 4469,  110,  100,   29,   12,   13, 5342,   16,  175,\n",
       "         29], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_layer (SimpleRNN) (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 648,321\n",
      "Trainable params: 648,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"simple_rnn_sequential\")\n",
    "model.add(Embedding(n_top_freq_words, \n",
    "                    embedding_dim, \n",
    "                    input_length=max_review_length, \n",
    "                    name=\"embedding_layer\")) \n",
    "model.add(SimpleRNN(units=embedding_dim, name=\"simple_rnn_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/simple_rnn_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 10s 493us/step - loss: 0.6324 - acc: 0.6164 - val_loss: 0.4640 - val_acc: 0.7828\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 9s 473us/step - loss: 0.3411 - acc: 0.8564 - val_loss: 0.4035 - val_acc: 0.8236\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 9s 471us/step - loss: 0.1885 - acc: 0.9304 - val_loss: 0.5190 - val_acc: 0.7738\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 10s 480us/step - loss: 0.0702 - acc: 0.9798 - val_loss: 0.6262 - val_acc: 0.7592\n",
      "25000/25000 [==============================] - 6s 254us/step\n",
      "Test score: 0.6038453269004822\n",
      "Test accuracy: 0.77156\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_class_seperation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_layer (SimpleRNN) (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 648,321\n",
      "Trainable params: 648,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_review_length,), name=\"input_layer\")\n",
    "embedding_layer = Embedding(n_top_freq_words, embedding_dim, name=\"embedding_layer\")(inputs)\n",
    "simple_rnn_layer = SimpleRNN(units=embedding_dim, name=\"simple_rnn_layer\")(embedding_layer)\n",
    "predictions = Dense(1, activation='sigmoid', name=\"dense_layer\")(simple_rnn_layer)\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=predictions,\n",
    "              name=\"simple_rnn_functional\")\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/simple_rnn_functional.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 10s 499us/step - loss: 0.6366 - acc: 0.6162 - val_loss: 0.4739 - val_acc: 0.7782\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 10s 480us/step - loss: 0.3467 - acc: 0.8522 - val_loss: 0.4106 - val_acc: 0.8294\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 10s 476us/step - loss: 0.1680 - acc: 0.9408 - val_loss: 0.5022 - val_acc: 0.7948\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 10s 475us/step - loss: 0.0602 - acc: 0.9834 - val_loss: 0.5811 - val_acc: 0.7992\n",
      "25000/25000 [==============================] - 7s 261us/step\n",
      "Test score: 0.5975196409416199\n",
      "Test accuracy: 0.79024\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 673,089\n",
      "Trainable params: 673,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"lstm_sequential\")\n",
    "model.add(Embedding(n_top_freq_words, \n",
    "                    embedding_dim, \n",
    "                    input_length=max_review_length, \n",
    "                    name=\"embedding_layer\")) \n",
    "model.add(LSTM(units=embedding_dim, name=\"lstm_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/lstm_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.4750 - acc: 0.7569 - val_loss: 0.3410 - val_acc: 0.8492\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2729 - acc: 0.8917 - val_loss: 0.3561 - val_acc: 0.8492\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2030 - acc: 0.9239 - val_loss: 0.3707 - val_acc: 0.8440\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.1580 - acc: 0.9449 - val_loss: 0.4176 - val_acc: 0.8406\n",
      "25000/25000 [==============================] - 11s 456us/step\n",
      "Test score: 0.43416643359184265\n",
      "Test accuracy: 0.83412\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_class_seperation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_layer (GRU)             (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 664,833\n",
      "Trainable params: 664,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"gru_sequential\")\n",
    "model.add(Embedding(n_top_freq_words, \n",
    "                    embedding_dim, \n",
    "                    input_length=max_review_length, \n",
    "                    name=\"embedding_layer\")) \n",
    "model.add(GRU(units=embedding_dim, name=\"lstm_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/gru_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "20000/20000 [==============================] - 20s 993us/step - loss: 0.4873 - acc: 0.7470 - val_loss: 0.3651 - val_acc: 0.8384\n",
      "Epoch 2/4\n",
      "20000/20000 [==============================] - 19s 961us/step - loss: 0.2712 - acc: 0.8899 - val_loss: 0.3557 - val_acc: 0.8464\n",
      "Epoch 3/4\n",
      "20000/20000 [==============================] - 19s 965us/step - loss: 0.2101 - acc: 0.9189 - val_loss: 0.3809 - val_acc: 0.8322\n",
      "Epoch 4/4\n",
      "20000/20000 [==============================] - 19s 972us/step - loss: 0.1744 - acc: 0.9365 - val_loss: 0.4747 - val_acc: 0.8306\n",
      "25000/25000 [==============================] - 11s 422us/step\n",
      "Test score: 0.49877956864833833\n",
      "Test accuracy: 0.82116\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEONJREFUeJzt3X+snmV9x/H3x1ZU/MEP2QhruxVjZUOWRdZgjYlj1vBLY0mmBDNHNY1NlDnnzDbc/ugCmkC2ySRRtk46i3EiY2Y0A0cahJgtK3oQh/wY44yf7UCUlrqsES1+98dz1R7wlOtwnqfneSjvV3Ly3Pd1X/f9fM/Vc/rpdd/3czdVhSRJz+ZF4y5AkjT5DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuhaPu4D5OuaYY2r58uXjLkN6unvuGbyecMJ465Bmceutt36/qn5uPvs+b8Ni+fLlTE1NjbsM6elOPXXwevPN46xCmlWSB+e7r6ehJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXc/bT3B/Z8dull9w3VhreODit4/1/SVpoTizkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUlc3LJJsSvJYkjtmtB2dZGuSe9vrUa09SS5LMp3k9iQnz9hnbet/b5K1M9p/Pcl32j6XJcmov0lJ0nDmMrP4PHDGM9ouAG6sqhXAjW0d4ExgRftaD1wOg3ABNgBvBE4BNuwLmNbnAzP2e+Z7SZLGrBsWVfV1YOczmtcAm9vyZuDsGe1X1sA24MgkxwGnA1uramdV7QK2Ame0ba+qqm1VVcCVM44lSZoQ871mcWxVPdKWHwWObctLgIdn9Nve2p6tffss7ZKkCTL0Be42I6gR1NKVZH2SqSRTT+3ZvRBvKUli/mHx3XYKifb6WGvfASyb0W9pa3u29qWztM+qqjZW1cqqWrno8CPmWbok6bmab1hsAfbd0bQWuHZG+3ntrqhVwO52uuoG4LQkR7UL26cBN7RtP0iyqt0Fdd6MY0mSJsTiXockXwJOBY5Jsp3BXU0XA1cnWQc8CJzTul8PnAVMA3uA9wNU1c4kFwHfbP0urKp9F80/xOCOq5cBX21fkqQJ0g2LqnrPATatnqVvAecf4DibgE2ztE8BJ/XqkCSNj5/gliR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1LR53AZL0QrD8guvGXcJQnFlIkroMC0lSl2EhSeoaKiySfDTJnUnuSPKlJC9NcnySW5JMJ/lyksNa35e09em2ffmM43y8td+T5PThviVJ0qjNOyySLAF+D1hZVScBi4BzgUuAS6vqtcAuYF3bZR2wq7Vf2vqR5MS23+uBM4DPJlk037okSaM37GmoxcDLkiwGDgceAd4KXNO2bwbObstr2jpt++okae1XVdWTVXU/MA2cMmRdkqQRmndYVNUO4C+AhxiExG7gVuCJqtrbum0HlrTlJcDDbd+9rf+rZ7bPss/TJFmfZCrJ1FN7ds+3dEnSczTMaaijGMwKjgd+AXg5g9NIB01VbayqlVW1ctHhRxzMt5IkzTDMaai3AfdX1feq6sfAV4A3A0e201IAS4EdbXkHsAygbT8CeHxm+yz7SJImwDBh8RCwKsnh7drDauAu4CbgXa3PWuDatrylrdO2f62qqrWf2+6WOh5YAXxjiLokSSM278d9VNUtSa4BvgXsBW4DNgLXAVcl+URru6LtcgXwhSTTwE4Gd0BRVXcmuZpB0OwFzq+qp+ZblyRp9IZ6NlRVbQA2PKP5Pma5m6mqfgi8+wDH+STwyWFqkSQdPH6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXUOFRZIjk1yT5D+T3J3kTUmOTrI1yb3t9ajWN0kuSzKd5PYkJ884ztrW/94ka4f9piRJozXszOLTwL9U1S8DvwbcDVwA3FhVK4Ab2zrAmcCK9rUeuBwgydHABuCNwCnAhn0BI0maDPMOiyRHAG8BrgCoqh9V1RPAGmBz67YZOLstrwGurIFtwJFJjgNOB7ZW1c6q2gVsBc6Yb12SpNEbZmZxPPA94O+S3Jbkc0leDhxbVY+0Po8Cx7blJcDDM/bf3toO1P4zkqxPMpVk6qk9u4coXZL0XAwTFouBk4HLq+oNwP+x/5QTAFVVQA3xHk9TVRuramVVrVx0+BGjOqwkqWOYsNgObK+qW9r6NQzC47vt9BLt9bG2fQewbMb+S1vbgdolSRNi3mFRVY8CDyc5oTWtBu4CtgD77mhaC1zblrcA57W7olYBu9vpqhuA05Ic1S5sn9baJEkTYvGQ+38Y+GKSw4D7gPczCKCrk6wDHgTOaX2vB84CpoE9rS9VtTPJRcA3W78Lq2rnkHVJkkZoqLCoqm8DK2fZtHqWvgWcf4DjbAI2DVOLJOng8RPckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtfQYZFkUZLbkvxzWz8+yS1JppN8Oclhrf0lbX26bV8+4xgfb+33JDl92JokSaM1ipnFR4C7Z6xfAlxaVa8FdgHrWvs6YFdrv7T1I8mJwLnA64EzgM8mWTSCuiRJIzJUWCRZCrwd+FxbD/BW4JrWZTNwdlte09Zp21e3/muAq6rqyaq6H5gGThmmLknSaA07s/gr4I+An7T1VwNPVNXetr4dWNKWlwAPA7Ttu1v/n7bPso8kaQLMOyySvAN4rKpuHWE9vfdcn2QqydRTe3Yv1NtK0gve4iH2fTPwziRnAS8FXgV8GjgyyeI2e1gK7Gj9dwDLgO1JFgNHAI/PaN9n5j5PU1UbgY0ALzluRQ1RuyTpOZj3zKKqPl5VS6tqOYML1F+rqt8GbgLe1bqtBa5ty1vaOm3716qqWvu57W6p44EVwDfmW5ckafSGmVkcyB8DVyX5BHAbcEVrvwL4QpJpYCeDgKGq7kxyNXAXsBc4v6qeOgh1SZLmaSRhUVU3Aze35fuY5W6mqvoh8O4D7P9J4JOjqEWSNHp+gluS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV3zDosky5LclOSuJHcm+UhrPzrJ1iT3ttejWnuSXJZkOsntSU6ecay1rf+9SdYO/21JkkZpmJnFXuBjVXUisAo4P8mJwAXAjVW1ArixrQOcCaxoX+uBy2EQLsAG4I3AKcCGfQEjSZoM8w6Lqnqkqr7Vlv8XuBtYAqwBNrdum4Gz2/Ia4Moa2AYcmeQ44HRga1XtrKpdwFbgjPnWJUkavZFcs0iyHHgDcAtwbFU90jY9ChzblpcAD8/YbXtrO1C7JGlCDB0WSV4B/CPw+1X1g5nbqqqAGvY9ZrzX+iRTSaae2rN7VIeVJHUMFRZJXswgKL5YVV9pzd9tp5dor4+19h3Ashm7L21tB2r/GVW1sapWVtXKRYcfMUzpkqTnYJi7oQJcAdxdVZ+asWkLsO+OprXAtTPaz2t3Ra0CdrfTVTcApyU5ql3YPq21SZImxOIh9n0z8DvAd5J8u7X9CXAxcHWSdcCDwDlt2/XAWcA0sAd4P0BV7UxyEfDN1u/Cqto5RF2SpBGbd1hU1b8COcDm1bP0L+D8AxxrE7BpvrVIkg4uP8EtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpa5gHCb7gLb/gunGXAMADF7993CVIOsQ5s5AkdTmzkHRIm5QzAM93ziwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSurx19hAwCbcG+sFAzWYSfjY1Gs4sJEldhoUkqcvTUBoJTzcMXHXf46x6zavHXYZ/Hho5w0IasW33Pc65/mWtQ4ynoSRJXYaFJKnLsJAkdRkWkqSuiQmLJGckuSfJdJILxl2PJGm/iQiLJIuAzwBnAicC70ly4nirkiTtMxFhAZwCTFfVfVX1I+AqYM2Ya5IkNZMSFkuAh2esb29tkqQJ8Lz6UF6S9cD6tvrkg5e8445x1jNBjgG+P+4iJsDYx+FN+xYuecc4y4AJGIsJ4ljsd8J8d5yUsNgBLJuxvrS1PU1VbQQ2AiSZqqqVC1PeZHMsBhyH/RyL/RyL/ZJMzXffSTkN9U1gRZLjkxwGnAtsGXNNkqRmImYWVbU3ye8CNwCLgE1VdeeYy5IkNRMRFgBVdT1w/XPYZePBquV5yLEYcBz2cyz2cyz2m/dYpKpGWYgk6RA0KdcsJEkTbKLDovcIkCQvSfLltv2WJMsXvsqFMYex+IMkdyW5PcmNSX5pHHUuhLk+GibJbyWpJIfsnTBzGYsk57SfjTuT/P1C17hQ5vA78otJbkpyW/s9OWscdS6EJJuSPJZk1o8XZOCyNla3Jzm5e9CqmsgvBhe6/xt4DXAY8B/Aic/o8yHgr9vyucCXx133GMfiN4HD2/IHX8hj0fq9Evg6sA1YOe66x/hzsQK4DTiqrf/8uOse41hsBD7Ylk8EHhh33QdxPN4CnAzccYDtZwFfBQKsAm7pHXOSZxZzeQTIGmBzW74GWJ0kC1jjQumORVXdVFV72uo2Bp9VORTN9dEwFwGXAD9cyOIW2FzG4gPAZ6pqF0BVPbbANS6UuYxFAa9qy0cA/7OA9S2oqvo6sPNZuqwBrqyBbcCRSY57tmNOcljM5REgP+1TVXuB3cD4/wPk0Xuuj0NZx+BfDYei7li0KfWyqjrU/2/TufxcvA54XZJ/S7ItyRkLVt3CmstY/Bnw3iTbGdx5+eGFKW0iPedHLE3MrbMajSTvBVYCvzHuWsYhyYuATwHvG3Mpk2Ixg1NRpzKYbX49ya9W1RNjrWo83gN8vqr+MsmbgC8kOamqfjLuwp4PJnlmMZdHgPy0T5LFDKaWjy9IdQtrTo9DSfI24E+Bd1bVkwtU20LrjcUrgZOAm5M8wOB87JZD9CL3XH4utgNbqurHVXU/8F8MwuNQM5exWAdcDVBV/w68lMFzo16I5vR3ykyTHBZzeQTIFmBtW34X8LVqV28OMd2xSPIG4G8YBMWhel4aOmNRVbur6piqWl5Vyxlcv3lnVc37mTgTbC6/I//EYFZBkmMYnJa6byGLXCBzGYuHgNUASX6FQVh8b0GrnBxbgPPaXVGrgN1V9ciz7TCxp6HqAI8ASXIhMFVVW4ArGEwlpxlczDl3fBUfPHMciz8HXgH8Q7vG/1BVvXNsRR8kcxyLF4Q5jsUNwGlJ7gKeAv6wqg652fccx+JjwN8m+SiDi93vO0T/cUmSLzH4R8Ix7RrNBuDFAFX11wyu2ZwFTAN7gPd3j3mIjpUkaYQm+TSUJGlCGBaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnr/wGugcM4oCJr7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_class_seperation(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
