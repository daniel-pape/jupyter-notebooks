{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network: IMDB example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import SimpleRNN, Embedding, Input\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility:\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_path = './img'\n",
    "\n",
    "if not os.path.isdir(img_path):\n",
    "    os.mkdir(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_vocabulary = 10000\n",
    "num_words = 500\n",
    "max_sentence_len = 200\n",
    "embedding_dim = 128\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change epochs to 4\n",
    "def train_and_eval(model, input_train, y_train, input_test, y_test):\n",
    "    model.fit(input_train,  \n",
    "              y_train,\n",
    "              epochs=1,\n",
    "              batch_size=batch_size,\n",
    "              validation_split=0.2)\n",
    "    \n",
    "    score, acc = model.evaluate(input_test, y_test)\n",
    "    \n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model(model):\n",
    "    from IPython.display import Image\n",
    "    from IPython.core.display import HTML \n",
    "    \n",
    "    path = './img/{}.png'.format(model.name)\n",
    "    plot_model(model, to_file=path)\n",
    "    \n",
    "    return Image(url=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consist of reviews for movies from IMDB, the Internet Movie Database. It contains reviews for 25,000 movies, each labeled by sentiment (positive/negative). \n",
    "\n",
    "Fortunately the data has already been preprocessed: each review is encoded as a sequence of word indexes (integers). The word index itself is the position of a word in the list of all unique words contained in all 25,000 movies ordered by their frequency (from most frequent words down to the most uncommon ones). So the word index \"3\" encodes the 3rd most frequent word in the data, which happens to be \"a\" like in \"a movie\".\n",
    "\n",
    "By convention, \"0\" does not stand for a specific word. Instead it is used to encode any unknown word and can be used for padding (see below).\n",
    "\n",
    "Here are some example reviews from IMDB:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Negative review examples:\n",
    "=========================\n",
    "* Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting.\n",
    "* Even those from the era should be turned off.\n",
    "* The cryptic dialogue would make Shakespeare seem easy to a third grader.\n",
    "\n",
    "Positive review examples:\n",
    "=========================\n",
    "* I didn't know this came from Canada, but it is very good. Very good!\n",
    "* I liked this movie a lot. It really intrigued me how Deanna and Alicia became friends over such a tragedy\n",
    "* When I saw the elaborate DVD box for this and the dreadful Red Queen figurine, \n",
    "  I felt certain I was in for a big disappointment, but surprise, surprise, I loved it. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data set and split it intro training and test sets. Notice than we only pick the `max_sentence_len` most commons words by setting `num_words=max_sentence_len`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=num_words, \n",
    "                                                              index_from=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an overview on how big the sets are. As it turns out the data is split in 50% for training and 50% for test. (Note: We cannot specify `test_split` for this data set in the `load_data` function.) As promised there are two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Shape train sequences: (25000,)\n",
      "Shape test sequences: (25000,)\n",
      "Shape train labels: (25000,)\n",
      "Shape test labels: (25000,)\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "\n",
    "print('Shape train sequences:', input_train.shape)\n",
    "print('Shape test sequences:', input_test.shape)\n",
    "print('Shape train labels:', y_train.shape)\n",
    "print('Shape test labels:', y_test.shape)\n",
    "print('Number of classes:', len(np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas to have a look at the first training samples. As said each of them is a list of word indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_index_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 11, 19, 13, 40, 2, 2, 2, 2, 62, 455, 2, 63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 191, 2, 191, 2, 75, 225, 2, 3, 2, 2, 2, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 11, 44, 5, 27, 28, 4, 1, 246, 105, 4, 1, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 2, 2, 30, 2, 1, 2, 429, 108, 150, 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 246, 2, 4, 58, 110, 7, 7, 10, 2, 11, 17, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 word_index_sequence\n",
       "0  [1, 11, 19, 13, 40, 2, 2, 2, 2, 62, 455, 2, 63...\n",
       "1  [1, 191, 2, 191, 2, 75, 225, 2, 3, 2, 2, 2, 13...\n",
       "2  [1, 11, 44, 5, 27, 28, 4, 1, 246, 105, 4, 1, 2...\n",
       "3  [1, 1, 2, 2, 30, 2, 1, 2, 429, 108, 150, 100, ...\n",
       "4  [1, 246, 2, 4, 58, 110, 7, 7, 10, 2, 11, 17, 5..."
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_train, columns=[\"word_index_sequence\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions loads the word index of the IMDB data set and allows us to translate a word index vector to a human readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(word_indizes: List[int]):\n",
    "    word_index = imdb.get_word_index()\n",
    "    inverse_word_index = {index:word for word, index in word_index.items()}\n",
    "    words = [inverse_word_index.get(wrd_idx, '<missing-word>') for wrd_idx in word_indizes]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious counter part for encoding a review as a word index vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(review: str):\n",
    "    word_index = imdb.get_word_index()\n",
    "    \n",
    "    return [word_index.get(word, 0) for word in review.lower().split(\" \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check everythings works fine by encoding and decoding an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'even those from the era should be turned <missing-word>'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Even those from the era should be turned off.\"\n",
    "decode(encode(review)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a real training example. (Note: Some words are clearly missing. Remember we limited ourself to the `num_words = 500` when loading the data via `imdb.load_data` above.) The review was favorable and thus gets a sentiment score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"and and and and to and well throughout director and and and a great and for the film the fact that most of it takes place and the and and and and that the film and very and and this and and the and idea of the and and to use and to and out of the and it's very and to get behind them it's often said that the and is the thing that really and people and this film and that as the director and that we can never really be sure of and what is and the and and this and to and that and actually does and to be quite and the film is and for a lot of and and the and plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone and that the film and and by the end and be and either as the ending both makes sense and and to be quite and overall and is a truly great horror film and one of the best of the and and and and\"\n",
      "\n",
      "Sentiment:  1\n"
     ]
    }
   ],
   "source": [
    "print('Review: \"{}\"\\n'.format(decode(input_train[10])))\n",
    "print('Sentiment: ', y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = sequence.pad_sequences(input_train, maxlen=max_sentence_len)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=max_sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_train shape: (25000, 200)\n",
      "input_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  22,  97,  40,   2, 109,  47,   2,   2,   6,  32, 477, 281,\n",
       "         2, 147,   1, 169, 109, 164,   2, 333, 382,  36,   1, 169,   2,\n",
       "         2,  14,   2,  35,  10, 444,   1, 189,  47,  13,   3, 144,   2,\n",
       "        16,  11,  19,   1,   2,   2, 466,   1,  19,  68,  84,   9,  13,\n",
       "        40,   2,  35,  73,  12,  10,   2,   1,  19,  14,   2,  14,   9,\n",
       "        13,   2,  15,   2,   2,  59, 383,   9,   5, 313,   5, 103,   2,\n",
       "         1,   2,   2,  13, 477,  63,   2,  30,   1, 127,   9,  13,  35,\n",
       "         2,   2,  22, 121,  48,  33, 132,  45,  22,   2,  30,   3,  19,\n",
       "         9, 212,  25,  74,  49,   2,  11, 404,  13,  79,   2,   5,   1,\n",
       "       104, 114,   2,  12, 253,   1,   2,   4,   2,   2,   2,  33,  68,\n",
       "        40,   2, 473,  23, 397, 314,  43,   4,   1,   2,   2,  10, 101,\n",
       "        85,   1, 378,  12, 294,  95,  29,   2,  53,  23, 138,   3, 191,\n",
       "         2,  15,   1, 223,  19,  18, 131, 473,  23, 477,   2, 141,  27,\n",
       "         2,  15,  48,  33,  25, 221,  89,  22, 101,   1, 223,  62,  13,\n",
       "        35,   2,  85,   9,  13, 280,   2,  13,   2, 110, 100,  29,  12,\n",
       "        13,   2,  16, 175,  29], dtype=int32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_layer (SimpleRNN) (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,313,025\n",
      "Trainable params: 1,313,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"simple_rnn_sequential\")\n",
    "model.add(Embedding(size_vocabulary, embedding_dim, name=\"embedding_layer\")) \n",
    "model.add(SimpleRNN(units=embedding_dim, name=\"simple_rnn_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/simple_rnn_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 61s 3ms/step - loss: 0.6872 - acc: 0.5420 - val_loss: 0.6681 - val_acc: 0.5760\n",
      "25000/25000 [==============================] - 36s 1ms/step\n",
      "Test score: 0.6672063104057312\n",
      "Test accuracy: 0.58304\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 500, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_layer (SimpleRNN) (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,313,025\n",
      "Trainable params: 1,313,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_sentence_len,), name=\"input_layer\")\n",
    "embedding_layer = Embedding(size_vocabulary, embedding_dim, name=\"embedding_layer\")(inputs)\n",
    "simple_rnn_layer = SimpleRNN(units=embedding_dim, name=\"simple_rnn_layer\")(embedding_layer)\n",
    "predictions = Dense(1, activation='sigmoid', name=\"dense_layer\")(simple_rnn_layer)\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=predictions,\n",
    "              name=\"simple_rnn_functional\")\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/simple_rnn_functional.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 60s 3ms/step - loss: 0.6817 - acc: 0.5533 - val_loss: 0.6518 - val_acc: 0.6180\n",
      "25000/25000 [==============================] - 38s 2ms/step\n",
      "Test score: 0.6479414934921265\n",
      "Test accuracy: 0.62892\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,411,713\n",
      "Trainable params: 1,411,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"lstm_sequential\")\n",
    "model.add(Embedding(size_vocabulary, embedding_dim, name=\"embedding_layer\")) \n",
    "model.add(LSTM(units=embedding_dim, name=\"lstm_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/lstm_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval(model, input_train, y_train, input_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (GRU)             (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,378,817\n",
      "Trainable params: 1,378,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"gru_sequential\")\n",
    "model.add(Embedding(size_vocabulary, embedding_dim, name=\"embedding_layer\")) \n",
    "model.add(GRU(units=embedding_dim, name=\"lstm_layer\"))\n",
    "model.add(Dense(1, activation='sigmoid', name=\"dense_layer\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./img/gru_sequential.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
